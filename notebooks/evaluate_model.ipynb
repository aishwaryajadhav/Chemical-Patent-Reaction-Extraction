{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anjadhav/miniconda3/envs/chemIR/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda =  True  with num_workers =  8  system version =  3.7.13 (default, Oct 18 2022, 18:57:03) \n",
      "[GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from utils import *\n",
    "from dataset  import *\n",
    "from models import *\n",
    "import wandb\n",
    "from collections import defaultdict\n",
    "# Check if cuda is available and set device\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "# Make sure you choose suitable num_worker, otherwise it will result in errors\n",
    "num_workers = 8 if cuda else 0\n",
    "\n",
    "print(\"Cuda = \", str(cuda), \" with num_workers = \", str(num_workers),  \" system version = \", sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_seq_len = 16  #number of paras to be encoded and decoded together (hyperparameter)\n",
    "batch_size = 4\n",
    "max_para_length = 128\n",
    "pretrained_model = \"recobo/chemical-bert-uncased-pharmaceutical-chemical-classifier\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "test_file = \"/home/anjadhav/Chemical-Patent-Reaction-Extraction/data/test_data_iob.csv\"\n",
    "test_data = CRFEmbeddingDataset(test_file, para_seq_len = para_seq_len, pretrained_model = pretrained_model, stride = para_seq_len)\n",
    "test_args = dict(shuffle=False, batch_size=batch_size, num_workers=8, pin_memory=True, drop_last=False) if cuda else dict(shuffle=False, batch_size=batch_size, drop_last=False)\n",
    "test_loader = DataLoader(test_data, **test_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "val_file = \"/home/anjadhav/Chemical-Patent-Reaction-Extraction/data/val_data_iob.csv\"\n",
    "val_data = CRFEmbeddingDataset(val_file, para_seq_len = para_seq_len, pretrained_model = pretrained_model, stride = para_seq_len)\n",
    "val_args = dict(shuffle=False, batch_size=batch_size, num_workers=8, pin_memory=True, drop_last=False) if cuda else dict(shuffle=False, batch_size=batch_size, drop_last=False)\n",
    "val_loader = DataLoader(val_data, **val_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "gen_file = \"/home/anjadhav/Chemical-Patent-Reaction-Extraction/data/organic_chem_patents.csv\"\n",
    "gen_data = CRFEmbeddingDataset(gen_file, para_seq_len = para_seq_len, pretrained_model = pretrained_model, stride = para_seq_len)\n",
    "gen_args = dict(shuffle=False, batch_size=batch_size, num_workers=8, pin_memory=True, drop_last=False) if cuda else dict(shuffle=False, batch_size=batch_size, drop_last=False)\n",
    "gen_loader = DataLoader(gen_data, **gen_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluate:\n",
    "    def __init__(self, model_load_path, pretrained_model, description = \"\"):\n",
    "        \n",
    "        print(description)\n",
    "\n",
    "        self.model_load_path = model_load_path\n",
    "        self.pretrained_model = pretrained_model\n",
    "\n",
    "        self.model = EncoderDecoderBiLstmCRF(embed_model = BertEmbedding(pretrained_model), num_tags = 3, freeze_bert=False)\n",
    "        self.model.load_state_dict(torch.load(model_load_path))\n",
    "        # model = load_pretrained_weights(model, './model_model_params_0.9428545098368426.pth')\n",
    "        self.model = self.model.to(device)\n",
    "\n",
    "        self.wandb = wandb.init(name=model_load_path, project=\"ChemIR3\") \n",
    "        self.wandb_table = wandb.Table(columns=['run', 'gen_eval_accuracy', 'gen_eval_f-1', 'gen_eval_precision', 'gen_eval_recall', 'gen_fuzzy_f1', 'gen_fuzzy_match_count', 'gen_fuzzy_precision', 'gen_fuzzy_recall', 'gen_misaligned_begin', 'gen_misaligned_begin_end_count', 'gen_misaligned_end', 'gen_missed_span_count', 'gen_strict_f1', 'gen_strict_precision', 'gen_strict_recall',  'test_eval_accuracy', 'test_eval_f-1', 'test_eval_precision', 'test_eval_recall', 'test_fuzzy_f1', 'test_fuzzy_match_count', 'test_fuzzy_precision', 'test_fuzzy_recall', 'test_misaligned_begin', 'test_misaligned_begin_end_count', 'test_misaligned_end', 'test_missed_span_count', 'test_strict_f1', 'test_strict_precision', 'test_strict_recall', 'validate_eval_accuracy', 'validate_eval_f-1', 'validate_eval_precision', 'validate_eval_recall', 'validate_fuzzy_f1', 'validate_fuzzy_match_count', 'validate_fuzzy_precision', 'validate_fuzzy_recall', 'validate_misaligned_begin', 'validate_misaligned_begin_end_count', 'validate_misaligned_end', 'validate_missed_span_count', 'validate_strict_f1', 'validate_strict_precision', 'validate_strict_recall'])     \n",
    "\n",
    "\n",
    "    def wandb_update(self, val_scores, test_scores, gen_scores):\n",
    "        val_scores.update(test_scores)\n",
    "        val_scores.update(gen_scores)\n",
    "        columns = sorted(list(val_scores.keys()))\n",
    "        wandb_update_list = [self.model_load_path] #run name\n",
    "        wandb_update_list.extend([val_scores[k] for k in columns])\n",
    "        self.wandb_table.add_data(*wandb_update_list)\n",
    "        self.wandb.log({\"gen\": self.wandb_table})\n",
    "    \n",
    "\n",
    "        \n",
    "    def evaluate(self, test_loader, test_file, wandb_name = \"test_\"):\n",
    "        test_df = pd.read_csv(test_file)\n",
    "        _, test_predictions, test_scores_validation = validate(self.model, test_loader, device, None, None, wandb = wandb_name)\n",
    "        _, test_scores_span_perf = get_span_perf(test_df, test_predictions, wandb = wandb_name)\n",
    "        \n",
    "        test_scores_validation.update(test_scores_span_perf)\n",
    "        print(test_scores_validation)\n",
    "        return test_scores_validation\n",
    "        \n",
    "\n",
    "    def extract_eval(self,  test_loader, test_file, save_name):\n",
    "        test_df = pd.read_csv(test_file)\n",
    "        test_predictions = extract(self.model, test_loader, device)\n",
    "        test_df, pred_spans = get_spans(test_df, test_predictions)\n",
    "        print(pred_spans)\n",
    "        test_df.to_csv(\"../outputs/\"+save_name)\n",
    "\n",
    "\n",
    "def load_pretrained_weights(model, pretrained_path):\n",
    "    pretrained_dict = torch.load(pretrained_path)\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k[:12] != \"crf_model.\"}\n",
    "\n",
    "    model_dict = model.state_dict()\n",
    "    model_dict.update(pretrained_dict) \n",
    "    model.load_state_dict(model_dict)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chem_bert_iob_bilstm_crf_bert_finetune/enc_dec_model_model_params_0.9525667530577686.pth\n",
      "pretrained_model = \"recobo/chemical-bert-uncased-pharmaceutical-chemical-classifier\"\n",
      "batch_size = 4\n",
      "max_para_length = 128\n",
      "para_seq_len = 16  #number of paras to be encoded and decoded together (hyperparameter)\n",
      "'./model_model_params_0.9428545098368426.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at recobo/chemical-bert-uncased-pharmaceutical-chemical-classifier were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:78qkxd0s) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">../models/chem_bert_iob_bilstm_crf_no_ft/model_model_params_0.9231656973050348.pth</strong>: <a href=\"https://wandb.ai/anjadhav_cmu/ChemIR3/runs/78qkxd0s\" target=\"_blank\">https://wandb.ai/anjadhav_cmu/ChemIR3/runs/78qkxd0s</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221122_133821-78qkxd0s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:78qkxd0s). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/anjadhav/Chemical-Patent-Reaction-Extraction/notebooks/wandb/run-20221122_133914-b5t9k9n9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/anjadhav_cmu/ChemIR3/runs/b5t9k9n9\" target=\"_blank\">../models/chem_bert_iob_bilstm_crf_bert_finetune/enc_dec_model_model_params_0.9525667530577686.pth</a></strong> to <a href=\"https://wandb.ai/anjadhav_cmu/ChemIR3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "description= \"\"\"./chem_bert_iob_bilstm_crf_bert_finetune/enc_dec_model_model_params_0.9525667530577686.pth\n",
    "pretrained_model = \"recobo/chemical-bert-uncased-pharmaceutical-chemical-classifier\"\n",
    "batch_size = 4\n",
    "max_para_length = 128\n",
    "para_seq_len = 16  #number of paras to be encoded and decoded together (hyperparameter)\n",
    "'./model_model_params_0.9428545098368426.pth'\"\"\"\n",
    "\n",
    "eval_model1 = Evaluate(model_load_path = '../models/chem_bert_iob_bilstm_crf_bert_finetune/enc_dec_model_model_params_0.9525667530577686.pth', pretrained_model = pretrained_model, description = description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "print(\"==========================Validation Data===================================\")\n",
    "val_scores = eval_model1.evaluate(val_loader, val_file, wandb_name = \"validate_\")\n",
    "\n",
    "print(\"===================================Test Data===================================\")\n",
    "test_scores =  eval_model1.evaluate(test_loader, test_file, wandb_name = \"test_\")\n",
    "\n",
    "print(\"===================================Gen Data===================================\")\n",
    "gen_scores = eval_model1.evaluate(gen_loader, gen_file, wandb_name = \"gen_\")\n",
    "\n",
    "eval_model1.wandb_update(val_scores, test_scores, gen_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 2.7918248176574707\n",
      "Index(['para', 'label', 'document', 'predictions'], dtype='object')\n",
      "{(726, 727), (555, 555), (557, 557), (710, 710), (715, 715), (717, 717), (723, 723), (556, 556), (716, 716), (711, 711), (724, 724), (712, 713), (558, 559), (479, 480), (923, 925), (720, 721), (241, 242), (709, 709), (708, 708), (926, 928), (473, 474), (921, 922), (562, 562), (718, 718), (483, 484), (475, 476), (719, 719), (239, 240), (730, 730), (477, 478), (729, 729), (728, 728), (706, 707), (467, 468), (471, 472), (243, 244), (247, 248), (481, 482), (560, 561), (731, 731), (733, 733), (714, 714), (469, 470), (237, 238), (245, 246), (732, 732), (725, 725), (722, 722), (223, 223)}\n"
     ]
    }
   ],
   "source": [
    "eval_model1.extract_eval(gen_loader, gen_file, \"gen_model1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/chem_bert_iob_bilstm_crf_no_ft/model_model_params_0.9231656973050348.pth\n",
      "pretrained_model = \"recobo/chemical-bert-uncased-pharmaceutical-chemical-classifier\"\n",
      "batch_size = 4\n",
      "max_para_length = 128\n",
      "para_seq_len = 16  #number of paras to be encoded and decoded together (hyperparameter)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at recobo/chemical-bert-uncased-pharmaceutical-chemical-classifier were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:b5t9k9n9) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">../models/chem_bert_iob_bilstm_crf_bert_finetune/enc_dec_model_model_params_0.9525667530577686.pth</strong>: <a href=\"https://wandb.ai/anjadhav_cmu/ChemIR3/runs/b5t9k9n9\" target=\"_blank\">https://wandb.ai/anjadhav_cmu/ChemIR3/runs/b5t9k9n9</a><br/>Synced 6 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221122_133914-b5t9k9n9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:b5t9k9n9). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/anjadhav/Chemical-Patent-Reaction-Extraction/notebooks/wandb/run-20221122_134016-hhxunght</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/anjadhav_cmu/ChemIR3/runs/hhxunght\" target=\"_blank\">../models/chem_bert_iob_bilstm_crf_no_ft/model_model_params_0.9231656973050348.pth</a></strong> to <a href=\"https://wandb.ai/anjadhav_cmu/ChemIR3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "description= \"\"\"../models/chem_bert_iob_bilstm_crf_no_ft/model_model_params_0.9231656973050348.pth\n",
    "pretrained_model = \"recobo/chemical-bert-uncased-pharmaceutical-chemical-classifier\"\n",
    "batch_size = 4\n",
    "max_para_length = 128\n",
    "para_seq_len = 16  #number of paras to be encoded and decoded together (hyperparameter)\n",
    "\"\"\"\n",
    "\n",
    "eval_model2 = Evaluate(model_load_path = '../models/chem_bert_iob_bilstm_crf_no_ft/model_model_params_0.9231656973050348.pth', pretrained_model = pretrained_model, description = description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "print(\"==========================Validation Data===================================\")\n",
    "val_scores = eval_model2.evaluate(val_loader, val_file, wandb_name = \"validate_\")\n",
    "\n",
    "print(\"===================================Test Data===================================\")\n",
    "test_scores =  eval_model2.evaluate(test_loader, test_file, wandb_name = \"test_\")\n",
    "\n",
    "print(\"===================================Gen Data===================================\")\n",
    "gen_scores = eval_model2.evaluate(gen_loader, gen_file, wandb_name = \"gen_\")\n",
    "\n",
    "eval_model2.wandb_update(val_scores, test_scores, gen_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 2.763430118560791\n",
      "Index(['para', 'label', 'document', 'predictions'], dtype='object')\n",
      "{(726, 727), (557, 557), (715, 715), (710, 710), (717, 717), (723, 723), (725, 725), (556, 556), (716, 716), (711, 711), (724, 724), (558, 559), (926, 927), (479, 480), (923, 925), (241, 242), (720, 721), (707, 707), (709, 709), (708, 708), (473, 474), (921, 922), (562, 562), (706, 706), (718, 718), (475, 476), (239, 240), (719, 719), (483, 484), (560, 560), (730, 730), (477, 478), (729, 729), (728, 728), (920, 920), (471, 472), (467, 468), (243, 244), (247, 248), (481, 482), (235, 236), (731, 731), (733, 733), (714, 714), (237, 238), (245, 246), (469, 470), (732, 732), (713, 713), (712, 712), (722, 722)}\n"
     ]
    }
   ],
   "source": [
    "eval_model2.extract_eval(gen_loader, gen_file, \"gen_model2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/chem_bert_iob_bilstm_crf_no_ft/model_model_params_0.9231656973050348.pth\n",
      "pretrained_model = \"recobo/chemical-bert-uncased-pharmaceutical-chemical-classifier\"\n",
      "batch_size = 4\n",
      "max_para_length = 128\n",
      "para_seq_len = 16  #number of paras to be encoded and decoded together (hyperparameter)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at recobo/chemical-bert-uncased-pharmaceutical-chemical-classifier were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:hhxunght) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">../models/chem_bert_iob_bilstm_crf_no_ft/model_model_params_0.9231656973050348.pth</strong>: <a href=\"https://wandb.ai/anjadhav_cmu/ChemIR3/runs/hhxunght\" target=\"_blank\">https://wandb.ai/anjadhav_cmu/ChemIR3/runs/hhxunght</a><br/>Synced 6 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221122_134016-hhxunght/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:hhxunght). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/anjadhav/Chemical-Patent-Reaction-Extraction/notebooks/wandb/run-20221122_134118-2s3lymzc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/anjadhav_cmu/ChemIR3/runs/2s3lymzc\" target=\"_blank\">../models/chem_bert_iob_bilstm_crf_no_ft/model_model_params_0.9231656973050348.pth</a></strong> to <a href=\"https://wandb.ai/anjadhav_cmu/ChemIR3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "description= \"\"\"../models/chem_bert_iob_bilstm_crf_no_ft/model_model_params_0.9231656973050348.pth\n",
    "pretrained_model = \"recobo/chemical-bert-uncased-pharmaceutical-chemical-classifier\"\n",
    "batch_size = 4\n",
    "max_para_length = 128\n",
    "para_seq_len = 16  #number of paras to be encoded and decoded together (hyperparameter)\n",
    "\"\"\"\n",
    "\n",
    "eval_model3 = Evaluate(model_load_path = '../models/chem_bert_iob_bilstm_crf_no_ft/model_model_params_0.9231656973050348.pth', pretrained_model = pretrained_model, description = description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "print(\"==========================Validation Data===================================\")\n",
    "val_scores = eval_model3.evaluate(val_loader, val_file, wandb_name = \"validate_\")\n",
    "\n",
    "print(\"===================================Test Data===================================\")\n",
    "test_scores =  eval_model3.evaluate(test_loader, test_file, wandb_name = \"test_\")\n",
    "\n",
    "print(\"===================================Gen Data===================================\")\n",
    "gen_scores = eval_model3.evaluate(gen_loader, gen_file, wandb_name = \"gen_\")\n",
    "\n",
    "eval_model3.wandb_update(val_scores, test_scores, gen_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 2.953927516937256\n",
      "Index(['para', 'label', 'document', 'predictions'], dtype='object')\n",
      "{(726, 727), (557, 557), (715, 715), (710, 710), (717, 717), (723, 723), (725, 725), (556, 556), (716, 716), (711, 711), (724, 724), (558, 559), (926, 927), (479, 480), (923, 925), (241, 242), (720, 721), (707, 707), (709, 709), (708, 708), (473, 474), (921, 922), (562, 562), (706, 706), (718, 718), (475, 476), (239, 240), (719, 719), (483, 484), (560, 560), (730, 730), (477, 478), (729, 729), (728, 728), (920, 920), (471, 472), (467, 468), (243, 244), (247, 248), (481, 482), (235, 236), (731, 731), (733, 733), (714, 714), (237, 238), (245, 246), (469, 470), (732, 732), (713, 713), (712, 712), (722, 722)}\n"
     ]
    }
   ],
   "source": [
    "eval_model3.extract_eval(gen_loader, gen_file, \"gen_model3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('chemIR': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bca01836d6106e973a10514ba84a22def982a0caf4526f342e9e0f31ef9581b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
